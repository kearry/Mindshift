# Functional Requirements

## User Accounts
- Users can register with a username, email, and password via `/api/auth/register`.
- Users can log in using username or email and password via NextAuth credentials or `/api/auth/login`.
- Logged in users have JWT-based sessions handled by NextAuth.
- Profiles store display name, bio, profile image URL, total points and rank.
- Users can follow and unfollow other users. A notification is created when a follow occurs.

## Topics
- Authenticated users can create new debate topics using `/api/topics`.
- Topic creation calls the AI service to determine the AI's initial stance and optional scale definitions using the selected LLM provider and model.
- Topics can be listed and viewed individually. Details include current AI stance, reasoning, and any associated debates.
- A topic can be deleted if it has no debates.

## Debates
- Authenticated users can start a debate on a topic specifying a goal direction (shift AI stance left toward support or right toward opposition).
- Each debate stores the LLM provider and model used for AI responses.
- Debates consist of alternating user arguments and AI responses for a maximum number of turns (default 5 per side).
- During each turn the AI generates a response and may adjust its stance using OpenAI or Ollama.
- Points are awarded based on how effectively the user shifts the AI's stance toward their goal.
- When a debate ends, a summary article is generated by OpenAI and stored with the debate.
- Debates can be commented on by authenticated users. Notifications are sent to the debate owner when new comments are posted.

## Retrieval-Augmented Generation (RAG)
- Past arguments are embedded and stored in a LanceDB vector table for retrieval.
- When generating an AI response, relevant context is retrieved from the vector database using embeddings of the user argument.
- A simplified `/api/rag` endpoint currently returns mock context if database access fails.

## Notifications
- Users receive notifications for new followers and comments on their debates.
- Notifications can be fetched and marked as read via `/api/notifications`.

## Leaderboard
- The `/api/leaderboard` endpoint returns the top users ordered by total points.

## Environment Configuration
- `.env` defines API keys and defaults for LLM provider, model, and vector database paths.
- The default LLM provider can be OpenAI or a local Ollama instance.

